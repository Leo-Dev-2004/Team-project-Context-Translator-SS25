# ğŸ›ï¸ Projekt-Architektur: Real-time Contextual Assistant

## ğŸŒŸ Ãœberblick

Der **Real-time Contextual Assistant** ist ein KI-gestÃ¼tzter Desktop-Assistent, der in Echtzeit kontextbezogene ErklÃ¤rungen wÃ¤hrend Live-GesprÃ¤chen liefert. Das System basiert auf einer modernen, serviceorientierten Architektur, die fÃ¼r hochleistungsfÃ¤hige Echtzeit-KI-Verarbeitung ausgelegt ist.

### KernfunktionalitÃ¤ten
- **Echtzeit-Spracherkennung**: Kontinuierliche Erfassung und Umwandlung von Mikrofon-Audio zu Text
- **KI-gestÃ¼tzte Terminologie-Erkennung**: Automatische Identifikation komplexer Fachbegriffe
- **Sofortige Kontextualisierung**: Generierung prÃ¤gnanter ErklÃ¤rungen fÃ¼r erkannte Begriffe
- **Desktop-Integration**: Native Electron-Anwendung mit benutzerfreundlicher OberflÃ¤che

## ğŸ—ï¸ System-Architektur

Die Anwendung besteht aus vier unabhÃ¤ngigen Hauptkomponenten, die Ã¼ber WebSockets in Echtzeit kommunizieren:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   System Runner     â”‚    â”‚   STT-Modul        â”‚    â”‚   Backend (FastAPI) â”‚
â”‚   (Master-Skript)   â”‚    â”‚   (Speech-to-Text) â”‚    â”‚   (Zentrale Logik)  â”‚
â”‚                     â”‚    â”‚                     â”‚    â”‚                     â”‚
â”‚ â€¢ ProzessÃ¼berwachungâ”‚    â”‚ â€¢ Audio-Erfassung   â”‚    â”‚ â€¢ Client-Management â”‚
â”‚ â€¢ Service-Koordin.  â”‚    â”‚ â€¢ Whisper-STT       â”‚    â”‚ â€¢ Message-Routing   â”‚
â”‚ â€¢ Lifecycle-Mgmt.   â”‚    â”‚ â€¢ Echtzeit-Stream   â”‚    â”‚ â€¢ KI-Pipeline       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                          â”‚                          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Frontend (Electron) â”‚
                    â”‚  (Desktop-GUI)      â”‚
                    â”‚                     â”‚
                    â”‚ â€¢ UI-Komponenten    â”‚
                    â”‚ â€¢ Session-Mgmt.     â”‚
                    â”‚ â€¢ Explanation-View  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. System Runner (`SystemRunner.py`)
**Rolle**: Master-Koordinator fÃ¼r alle Systemkomponenten
- **Prozess-Management**: Startet, Ã¼berwacht und beendet alle anderen Services
- **Koordination**: Stellt sicher, dass Backend, STT-Modul und Frontend ordnungsgemÃ¤ÃŸ initialisiert werden
- **Fehlerbehandlung**: Ãœberwachung der Service-Gesundheit und automatisches Neustarten bei Bedarf
- **Session-Management**: Generiert eindeutige User-Session-IDs fÃ¼r die Sitzungsverfolgung

### 2. STT-Modul (`Backend/STT/`)
**Rolle**: Hochleistungs-Spracherkennung
- **Audio-Pipeline**: Kontinuierliche Mikrofon-Erfassung mit optimierter Pufferung
- **Whisper-Integration**: Verwendung von faster-whisper fÃ¼r prÃ¤zise Speech-to-Text-Umwandlung
- **Streaming-Optimierung**: Chunk-basierte Verarbeitung fÃ¼r minimale Latenz
- **WebSocket-Kommunikation**: Direkter Stream von Transkriptionen zum Backend

### 3. Backend (`Backend/backend.py`)
**Rolle**: Zentrale Intelligenz und Orchestrierung
- **FastAPI-Server**: Asynchrone HTTP/WebSocket-API auf Port 8000
- **Message-Routing**: Intelligente Weiterleitung zwischen Services Ã¼ber `MessageRouter`
- **KI-Pipeline**: Zweistufige AI-Verarbeitung (SmallModel â†’ MainModel)
- **Client-Management**: Multi-Client-UnterstÃ¼tzung mit Session-Isolation
- **Settings-Management**: Zentralisierte Konfigurationsverwaltung

#### Backend-Kernkomponenten

##### Message Queue System
```python
# Zentrale Queue-Architektur
queues = {
    'incoming': MessageQueue(),      # STT â†’ Backend
    'detection': MessageQueue(),     # Backend â†’ SmallModel  
    'main_model': MessageQueue(),    # SmallModel â†’ MainModel
    'websocket_out': MessageQueue()  # MainModel â†’ Frontend
}
```

##### Zweistufige KI-Verarbeitung
1. **SmallModel** (`Backend/models/SmallModel.py`)
   - Schnelle Terminologie-Erkennung mit Ollama
   - Domain-spezifische Filterung basierend auf User-Settings
   - Lightweight-Modell fÃ¼r Echtzeit-Performance

2. **MainModel** (`Backend/models/MainModel.py`)
   - Detaillierte ErklÃ¤rungsgenerierung 
   - Kontextbewusste Prompt-Konstruktion
   - Integration mit globalen Settings (Domain, ErklÃ¤rungsstil)

### 4. Frontend (`Frontend/`)
**Rolle**: Desktop-UI und User-Interaktion
- **Electron-App**: Cross-Platform Desktop-Anwendung
- **WebSocket-Client**: Echtzeit-Verbindung zum Backend (ws://localhost:8000)
- **Lit-Komponenten**: Moderne Web-Components fÃ¼r reactive UI
- **Explanation-Management**: Lokale Speicherung und Darstellung von KI-ErklÃ¤rungen

## ğŸ”„ Datenfluss und Interaktionen

### Hauptdatenfluss: Audio â†’ ErklÃ¤rung
```
1. Mikrofon-Audio
   â”‚
   â–¼
2. STT-Modul (Whisper)
   â”‚ (WebSocket)
   â–¼
3. Backend Message-Router
   â”‚
   â–¼
4. SmallModel (Terminologie-Erkennung)
   â”‚
   â–¼
5. MainModel (ErklÃ¤rungsgenerierung)
   â”‚ (WebSocket)
   â–¼
6. Frontend (UI-Darstellung)
```

### Settings-Synchronisation
Das System implementiert eine bidirektionale Settings-Synchronisation zwischen Frontend und Backend:

1. **Frontend â†’ Backend**: User-Ã„nderungen werden via WebSocket Ã¼bertragen
2. **Backend-Persistierung**: Settings werden in `Backend/settings.json` gespeichert
3. **AI-Integration**: SmallModel und MainModel konsumieren Settings fÃ¼r kontextuelle Verarbeitung

### Session-Management
- **Session-Erstellung**: User kann neue Sessions starten oder bestehende beitreten
- **Client-Isolation**: Jede Session hat isolierte Message-Queues und Explanation-Stores
- **Multi-User-Support**: Backend unterstÃ¼tzt multiple gleichzeitige Sessions

## ğŸ’» Frontend-Architektur (Electron)

### Komponenten-Hierarchie
```
src/
â”œâ”€â”€ main.js              # Electron Main Process
â”œâ”€â”€ preload.js           # Secure API Bridge (CommonJS)
â”œâ”€â”€ renderer.js          # Renderer Entry + WebSocket Logic
â””â”€â”€ shared/              # Geteilte UI-Komponenten
    â”œâ”€â”€ ui.js            # Basis-UI-Komponente
    â”œâ”€â”€ explanation-manager.js    # Zentraler Store
    â”œâ”€â”€ universal-message-parser.js # Message-Parsing
    â”œâ”€â”€ explanation-item.js       # Einzelne ErklÃ¤rung
    â””â”€â”€ styles.js        # Style-System
```

### Technologie-Stack
- **Electron**: Native Desktop-Integration
- **Lit**: Reactive Web Components
- **Vite**: Moderne Build-Pipeline fÃ¼r Renderer
- **esbuild**: Preload-Script-Bundling
- **Material Web**: M3-konforme UI-Komponenten

### Sicherheitsmodell
- **Sandbox**: Renderer lÃ¤uft in eingeschrÃ¤nkter Umgebung
- **Preload-Bridge**: Minimale, sichere API-OberflÃ¤che
- **CSP**: Content Security Policy fÃ¼r localhost:5174 und :8000
- **IPC**: Sichere Kommunikation zwischen Main und Renderer

### Message-Protokoll
Alle WebSocket-Nachrichten folgen einem einheitlichen Schema:
```typescript
interface UniversalMessage {
  id: string
  type: string
  timestamp: number  // sec oder ms
  payload: any
  client_id: string
  origin: string
  destination: string
}
```

#### Wichtige Message-Types
- `session.start` / `session.join`: Session-Management
- `stt.transcript`: Transkriptions-Updates vom STT-Modul
- `explanation.generated`: Neue KI-ErklÃ¤rungen
- `settings.save`: Settings-Synchronisation
- `manual.request`: Manuelle ErklÃ¤rungsanfragen

## ğŸ› ï¸ Entwicklung und Deployment

### Entwicklungsumgebung
```bash
# Backend starten
python -m uvicorn Backend.backend:app --host 0.0.0.0 --port 8000

# Frontend entwickeln (aus Frontend/)  
npm run dev

# Komplettes System
python SystemRunner.py
```

### Build-Pipeline
- **Frontend**: `npm run build` (Vite + electron-builder)
- **Backend**: Python-Module mit requirements.txt
- **Distribution**: Electron-App-Pakete fÃ¼r Windows/Mac/Linux

### Konfiguration
- **Backend-Settings**: `Backend/settings.json`
- **Frontend-Settings**: `~/.context-translator-settings.json` (via Electron)
- **Environment**: `.env` fÃ¼r entwicklungsspezifische Konfiguration

### Logging und Monitoring
- **Zentralisiertes Logging**: Alle Komponenten loggen strukturiert
- **Prozess-Ãœberwachung**: SystemRunner Ã¼berwacht Service-Gesundheit
- **Performance-Metriken**: Queue-Status und Verarbeitungszeiten

## ğŸ”§ Wichtige Design-Prinzipien

### Lose Kopplung
- Services kommunizieren ausschlieÃŸlich Ã¼ber definierte Schnittstellen
- Jede Komponente kann unabhÃ¤ngig entwickelt und getestet werden
- Queue-basierte Architektur ermÃ¶glicht asynchrone Verarbeitung

### Skalierbarkeit
- Message-Queue-System unterstÃ¼tzt horizontale Skalierung
- Modular aufgebaute AI-Pipeline ermÃ¶glicht Model-Swapping
- Session-basierte Architektur fÃ¼r Multi-User-Szenarien

### Performance-Optimierung
- Streaming STT fÃ¼r minimale Audio-Latenz
- In-Memory-Caching fÃ¼r Settings und Sessions
- Asynchrone Verarbeitung an allen kritischen Punkten

### Benutzerfreundlichkeit
- Native Desktop-Integration Ã¼ber Electron
- Responsive UI mit sofortiger Feedback-Anzeige
- Persistente lokale Einstellungen und Explanation-Historie

---

*Dieses Architektur-Dokument wird kontinuierlich aktualisiert, um die Weiterentwicklung des Systems zu reflektieren.*